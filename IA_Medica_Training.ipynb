{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhnunes/AIModels/blob/UNET/IA_Medica_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvTIWO7c-1Sq"
      },
      "source": [
        "1. Set Up Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjyU6Sby9yf8",
        "outputId": "de832396-c4e3-4859-f6a6-574482133ea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install torch torchvision torchsummary numpy matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VSREfYu--6F"
      },
      "source": [
        "2. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YCF-2VS_BvL",
        "outputId": "8419d291-86f3-455a-b9d1-183d8e64862b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import functional as TF\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import gc\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQCnzwFoAW1K",
        "outputId": "8605bab5-3d75-4c85-90db-dc24cedecff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "# Define hyperparameters\n",
        "LEARNING_RATE = 1e-5\n",
        "BATCH_SIZE = 8\n",
        "NUM_EPOCHS = 100\n",
        "WORKERS = 12\n",
        "WEIGHT_DECAY = 1e-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sppPrN8HU5x"
      },
      "source": [
        "# ***Define METRICS FOR EVALUATION***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ltg9DyAHbm6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def dice_coefficient(pred, target, smooth=1e-6):\n",
        "    pred = pred.contiguous()\n",
        "    target = target.contiguous()\n",
        "\n",
        "    intersection = (pred & target).float().sum((1, 2))\n",
        "\n",
        "    dice = (2. * intersection + smooth) / (pred.float().sum((1, 2)) + target.float().sum((1, 2)) + smooth)\n",
        "\n",
        "    return dice.mean().item()\n",
        "\n",
        "def iou(pred, target, smooth=1e-6):\n",
        "    pred = pred.contiguous()\n",
        "    target = target.contiguous()\n",
        "\n",
        "    intersection = (pred & target).float().sum((1, 2))\n",
        "    union = (pred | target).float().sum((1, 2))\n",
        "\n",
        "    iou = (intersection + smooth) / (union + smooth)\n",
        "\n",
        "    return iou.mean().item()\n",
        "\n",
        "def pixel_accuracy(preds, masks):\n",
        "    correct = (preds == masks).sum().item()\n",
        "    total = masks.numel()\n",
        "    return correct / total\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeZtNhSF_FAf"
      },
      "source": [
        "3. Define Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvRqZN6Y_K5x"
      },
      "source": [
        "# ***UNET***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRnEt-uemMSz"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNet, self).__init__()\n",
        "        self.encoder = nn.ModuleList([\n",
        "            self.conv_block(in_channels, 64),\n",
        "            self.conv_block(64, 128),\n",
        "            self.conv_block(128, 256),\n",
        "            self.conv_block(256, 512),\n",
        "        ])\n",
        "        self.middle = self.conv_block(512, 1024)\n",
        "        self.decoder = nn.ModuleList([\n",
        "            self.up_conv_block(1024, 512),\n",
        "            self.up_conv_block(512, 256),\n",
        "            self.up_conv_block(256, 128),\n",
        "            self.up_conv_block(128, 64),\n",
        "        ])\n",
        "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def conv_block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def up_conv_block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
        "            self.conv_block(out_channels * 2, out_channels)  # *2 because of concatenation\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_layer in self.encoder:\n",
        "            x = encoder_layer(x)\n",
        "            encoder_outputs.append(x)\n",
        "            x = nn.functional.max_pool2d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        x = self.middle(x)\n",
        "\n",
        "        for decoder_layer, encoder_output in zip(self.decoder, reversed(encoder_outputs)):\n",
        "            x = decoder_layer[0](x)  # Upconvolution\n",
        "            x = torch.cat([x, encoder_output], dim=1)\n",
        "            x = decoder_layer[1](x)  # Conv block after concatenation\n",
        "\n",
        "        return self.final_conv(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_FoIufq_Q-r"
      },
      "source": [
        "4. Create Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Mu38bAUmhFj"
      },
      "outputs": [],
      "source": [
        "class ProstateCancerDataset(Dataset):\n",
        "    def __init__(self, cancer_image_dir, cancer_mask_dir, not_cancer_image_dir, not_cancer_mask_dir, image_transform=None, mask_transform=None):\n",
        "        self.cancer_image_dir = cancer_image_dir\n",
        "        self.cancer_mask_dir = cancer_mask_dir\n",
        "        self.not_cancer_image_dir = not_cancer_image_dir\n",
        "        self.not_cancer_mask_dir = not_cancer_mask_dir\n",
        "        self.image_transform = image_transform\n",
        "        self.mask_transform = mask_transform\n",
        "\n",
        "        # Combine image and mask file lists\n",
        "        self.cancer_images = os.listdir(cancer_image_dir)\n",
        "        self.not_cancer_images = os.listdir(not_cancer_image_dir)\n",
        "        self.images = self.cancer_images + self.not_cancer_images\n",
        "        self.labels = [1] * len(self.cancer_images) + [0] * len(self.not_cancer_images)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.labels[idx] == 1:\n",
        "            img_path = os.path.join(self.cancer_image_dir, self.images[idx])\n",
        "            mask_path = os.path.join(self.cancer_mask_dir, self.images[idx])\n",
        "        else:\n",
        "            img_path = os.path.join(self.not_cancer_image_dir, self.images[idx])\n",
        "            mask_path = os.path.join(self.not_cancer_mask_dir, self.images[idx])\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "\n",
        "        # Ensure image and mask have the same size\n",
        "        image = image.resize((224, 224), Image.BILINEAR)\n",
        "        mask = mask.resize((224, 224), Image.NEAREST)\n",
        "\n",
        "        if self.image_transform:\n",
        "            image = self.image_transform(image)\n",
        "        if self.mask_transform:\n",
        "            mask = self.mask_transform(mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qEoCkty_bw1"
      },
      "outputs": [],
      "source": [
        "class ToTensor:\n",
        "    def __call__(self, image):\n",
        "        image = TF.to_tensor(image)\n",
        "        return image\n",
        "\n",
        "class ToTensorMask:\n",
        "    def __call__(self, mask):\n",
        "        mask = torch.tensor(np.array(mask), dtype=torch.long)\n",
        "        return mask\n",
        "\n",
        "class Normalize:\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image):\n",
        "        image = TF.normalize(image, self.mean, self.std)\n",
        "        return image\n",
        "\n",
        "image_transform = transforms.Compose([\n",
        "    ToTensor(),\n",
        "    Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "mask_transform = transforms.Compose([\n",
        "    ToTensorMask(),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts4MwEAD_e73"
      },
      "source": [
        "5. Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kamQzhLY_hA5",
        "outputId": "66679e83-86d7-4a0f-f02e-42fd498bbb8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "# Directories\n",
        "train_cancer_image_dir = '/content/drive/MyDrive/SUB_SET_SMALL/TRAIN/CANCER'\n",
        "train_cancer_mask_dir = '/content/drive/MyDrive/SUB_SET_SMALL/TRAIN/CANCER_MASK'\n",
        "train_not_cancer_image_dir = '/content/drive/MyDrive/SUB_SET_SMALL/TRAIN/NOT_CANCER'\n",
        "train_not_cancer_mask_dir = '/content/drive/MyDrive/SUB_SET_SMALL/TRAIN/NOT_CANCER_MASK'\n",
        "\n",
        "val_cancer_image_dir = '/content/drive/MyDrive/SUB_SET_SMALL/VALIDATION/CANCER'\n",
        "val_cancer_mask_dir = '/content/drive/MyDrive/SUB_SET_SMALL/VALIDATION/CANCER_MASK'\n",
        "val_not_cancer_image_dir = '/content/drive/MyDrive/SUB_SET_SMALL/VALIDATION/NOT_CANCER'\n",
        "val_not_cancer_mask_dir = '/content/drive/MyDrive/SUB_SET_SMALL/VALIDATION/NOT_CANCER_MASK'\n",
        "\n",
        "test_cancer_image_dir = '/content/drive/MyDrive/SUB_SET_SMALL/TEST/CANCER'\n",
        "test_cancer_mask_dir = '/content/drive/MyDrive/SUB_SET_SMALL/TEST/CANCER_MASK'\n",
        "test_not_cancer_image_dir = '/content/drive/MyDrive/SUB_SET_SMALL/TEST/NOT_CANCER'\n",
        "test_not_cancer_mask_dir = '/content/drive/MyDrive/SUB_SET_SMALL/TEST/NOT_CANCER_MASK'\n",
        "\n",
        "# Datasets\n",
        "train_dataset = ProstateCancerDataset(train_cancer_image_dir, train_cancer_mask_dir, train_not_cancer_image_dir, train_not_cancer_mask_dir, image_transform=image_transform, mask_transform=mask_transform)\n",
        "val_dataset = ProstateCancerDataset(val_cancer_image_dir, val_cancer_mask_dir, val_not_cancer_image_dir, val_not_cancer_mask_dir, image_transform=image_transform, mask_transform=mask_transform)\n",
        "test_dataset = ProstateCancerDataset(test_cancer_image_dir, test_cancer_mask_dir, test_not_cancer_image_dir, test_not_cancer_mask_dir, image_transform=image_transform, mask_transform=mask_transform)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBKVYDnKFRZw"
      },
      "source": [
        "# ***Early Stop Class***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poSSQexYFULq"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model, path):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "            self.save_checkpoint(val_loss, model, path)\n",
        "        elif val_loss > self.best_loss + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.save_checkpoint(val_loss, model, path)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model, path):\n",
        "        \"\"\"Saves model when validation loss decreases.\"\"\"\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.best_loss:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uffYwsNdArXd"
      },
      "source": [
        "6. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmEPRcp3mZ0l"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, dataloader, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_pixels = 0\n",
        "    total_pixels = 0\n",
        "    for images, masks in dataloader:\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks.squeeze(1).long())  # Adjust target shape\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        correct_pixels += (preds == masks.squeeze(1)).sum().item()\n",
        "        total_pixels += masks.numel()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_accuracy = correct_pixels / total_pixels\n",
        "\n",
        "\n",
        "    return epoch_loss, epoch_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02vpCMSdAtYg"
      },
      "outputs": [],
      "source": [
        "def validate_model(model, criterion, dataloader, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct_pixels = 0\n",
        "    total_pixels = 0\n",
        "    with torch.no_grad():\n",
        "        for images, masks in dataloader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            #loss = criterion(outputs, masks)\n",
        "            loss = criterion(outputs, masks.squeeze(1).long())\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            correct_pixels += (preds == masks.squeeze(1)).sum().item()\n",
        "            total_pixels += masks.numel()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_accuracy = correct_pixels / total_pixels\n",
        "\n",
        "    return epoch_loss, epoch_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYZBS-4yAyf3"
      },
      "source": [
        "7. Initialize and Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jyz3DDG-A1J1",
        "outputId": "bfebb322-76ae-4165-8267-25804c860794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Train Loss: 0.6927, Train Accuracy: 0.5040, Validation Loss: 0.6905, Validation Accuracy: 0.4921, Learning Rate: 0.000010\n",
            "Validation loss decreased (0.690532 --> 0.690532).  Saving model ...\n",
            "Epoch 2/100, Train Loss: 0.6908, Train Accuracy: 0.5184, Validation Loss: 0.6865, Validation Accuracy: 0.5433, Learning Rate: 0.000010\n",
            "Validation loss decreased (0.686458 --> 0.686458).  Saving model ...\n",
            "Epoch 3/100, Train Loss: 0.6853, Train Accuracy: 0.5433, Validation Loss: 0.6821, Validation Accuracy: 0.5508, Learning Rate: 0.000010\n",
            "Validation loss decreased (0.682113 --> 0.682113).  Saving model ...\n",
            "Epoch 4/100, Train Loss: 0.6755, Train Accuracy: 0.5758, Validation Loss: 0.6690, Validation Accuracy: 0.5963, Learning Rate: 0.000010\n",
            "Validation loss decreased (0.668989 --> 0.668989).  Saving model ...\n",
            "Epoch 5/100, Train Loss: 0.6631, Train Accuracy: 0.6017, Validation Loss: 0.6626, Validation Accuracy: 0.6062, Learning Rate: 0.000010\n",
            "Validation loss decreased (0.662596 --> 0.662596).  Saving model ...\n",
            "Epoch 6/100, Train Loss: 0.6552, Train Accuracy: 0.6145, Validation Loss: 0.6567, Validation Accuracy: 0.6151, Learning Rate: 0.000010\n",
            "Validation loss decreased (0.656653 --> 0.656653).  Saving model ...\n",
            "Epoch 7/100, Train Loss: 0.6532, Train Accuracy: 0.6179, Validation Loss: 0.6609, Validation Accuracy: 0.6049, Learning Rate: 0.000010\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 8/100, Train Loss: 0.6504, Train Accuracy: 0.6217, Validation Loss: 0.6522, Validation Accuracy: 0.6193, Learning Rate: 0.000010\n",
            "Validation loss decreased (0.652234 --> 0.652234).  Saving model ...\n",
            "Epoch 9/100, Train Loss: 0.6477, Train Accuracy: 0.6253, Validation Loss: 0.6562, Validation Accuracy: 0.6096, Learning Rate: 0.000010\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 10/100, Train Loss: 0.6466, Train Accuracy: 0.6266, Validation Loss: 0.6501, Validation Accuracy: 0.6206, Learning Rate: 0.000010\n",
            "Validation loss decreased (0.650083 --> 0.650083).  Saving model ...\n",
            "Epoch 11/100, Train Loss: 0.6439, Train Accuracy: 0.6294, Validation Loss: 0.6476, Validation Accuracy: 0.6258, Learning Rate: 0.000010\n",
            "Validation loss decreased (0.647611 --> 0.647611).  Saving model ...\n",
            "Epoch 12/100, Train Loss: 0.6429, Train Accuracy: 0.6300, Validation Loss: 0.6491, Validation Accuracy: 0.6223, Learning Rate: 0.000010\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 13/100, Train Loss: 0.6407, Train Accuracy: 0.6333, Validation Loss: 0.6519, Validation Accuracy: 0.6122, Learning Rate: 0.000010\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 14/100, Train Loss: 0.6394, Train Accuracy: 0.6347, Validation Loss: 0.6430, Validation Accuracy: 0.6261, Learning Rate: 0.000010\n",
            "Validation loss decreased (0.643006 --> 0.643006).  Saving model ...\n",
            "Epoch 15/100, Train Loss: 0.6364, Train Accuracy: 0.6388, Validation Loss: 0.6582, Validation Accuracy: 0.6004, Learning Rate: 0.000010\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 16/100, Train Loss: 0.6361, Train Accuracy: 0.6386, Validation Loss: 0.6392, Validation Accuracy: 0.6337, Learning Rate: 0.000010\n",
            "Validation loss decreased (0.639201 --> 0.639201).  Saving model ...\n",
            "Epoch 17/100, Train Loss: 0.6345, Train Accuracy: 0.6402, Validation Loss: 0.6418, Validation Accuracy: 0.6262, Learning Rate: 0.000010\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 18/100, Train Loss: 0.6327, Train Accuracy: 0.6422, Validation Loss: 0.6404, Validation Accuracy: 0.6276, Learning Rate: 0.000010\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 19/100, Train Loss: 0.6316, Train Accuracy: 0.6436, Validation Loss: 0.6364, Validation Accuracy: 0.6376, Learning Rate: 0.000010\n",
            "Validation loss decreased (0.636381 --> 0.636381).  Saving model ...\n",
            "Epoch 20/100, Train Loss: 0.6318, Train Accuracy: 0.6435, Validation Loss: 0.6464, Validation Accuracy: 0.6149, Learning Rate: 0.000010\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 21/100, Train Loss: 0.6296, Train Accuracy: 0.6456, Validation Loss: 0.6377, Validation Accuracy: 0.6379, Learning Rate: 0.000010\n",
            "EarlyStopping counter: 2 out of 5\n"
          ]
        }
      ],
      "source": [
        "# Initialize and Train Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNet(in_channels=3, out_channels=2).to(device)  # 2 classes: CANCER and NOT_CANCER\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
        "\n",
        "num_epochs = NUM_EPOCHS\n",
        "early_stopping = EarlyStopping(patience=5, verbose=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_accuracy = train_model(model, criterion, optimizer, train_loader, device)\n",
        "    val_loss, val_accuracy = validate_model(model, criterion, val_loader, device)\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "    # Print training and validation metrics\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}, Learning Rate: {current_lr:.6f}\")\n",
        "\n",
        "    early_stopping(val_loss, model, 'best_model.pth')\n",
        "\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "    gc.collect()  # Trigger garbage collection\n",
        "    torch.cuda.empty_cache()  # Free up any cached CUDA allocations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNelBTUbA-03"
      },
      "source": [
        "8. Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StgE8keUBCVv"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    dice_score = 0.0\n",
        "    iou_score = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in dataloader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            dice_score += dice_coefficient(preds, masks)\n",
        "            iou_score += iou(preds, masks)\n",
        "            num_batches += 1\n",
        "\n",
        "    dice_score /= num_batches\n",
        "    iou_score /= num_batches\n",
        "\n",
        "    print(f\"Dice Coefficient: {dice_score:.4f}, IoU: {iou_score:.4f}\")\n",
        "    return dice_score, iou_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6cbE-N_BG4v"
      },
      "source": [
        "9. Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSW9nrPyBKYT"
      },
      "outputs": [],
      "source": [
        "# Load the best model\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "# Test the model\n",
        "dice, iou = evaluate_model(model, test_loader, device)\n",
        "\n",
        "def visualize_predictions(model, dataloader, device, num_images=5):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (images, masks) in enumerate(dataloader):\n",
        "            if i >= num_images:\n",
        "                break\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            images = images.cpu().numpy()\n",
        "            masks = masks.cpu().numpy()\n",
        "            preds = preds.cpu().numpy()\n",
        "\n",
        "            for j in range(images.shape[0]):\n",
        "                plt.figure(figsize=(10, 3))\n",
        "                plt.subplot(1, 3, 1)\n",
        "                plt.imshow(np.transpose(images[j], (1, 2, 0)))\n",
        "                plt.title('Image')\n",
        "                plt.subplot(1, 3, 2)\n",
        "                plt.imshow(masks[j])\n",
        "                plt.title('Ground Truth')\n",
        "                plt.subplot(1, 3, 3)\n",
        "                plt.imshow(preds[j])\n",
        "                plt.title('Prediction')\n",
        "                plt.show()\n",
        "\n",
        "# Visualize predictions\n",
        "visualize_predictions(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eqS2McOgwgg"
      },
      "outputs": [],
      "source": [
        "print(f'Dice Value = {dice} ===== IoU Value = {iou}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNvyQ4688pKpr3yD82qdsp3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}